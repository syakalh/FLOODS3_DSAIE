{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f95ae8-e369-4ed2-a62b-06040d542011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Useful libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "from cycler import cycler\n",
    "import seaborn as sns\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# for mac GPU \n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "# defining folder for conveniance\n",
    "folder = \"\" #\"C:\\Users\\luc\\Downloads\\GitHub\\FLOODS3_DSAIE\\raw_datasets\\DEM\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5df8e9-7e6e-4b63-86f6-233f8fa0c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset, scaler_x, scaler_y):\n",
    "    min_x, max_x = scaler_x.data_min_[0], scaler_x.data_max_[0]\n",
    "    min_y, max_y = scaler_y.data_min_[0], scaler_y.data_max_[0]\n",
    "    normalized_dataset = []\n",
    "    for idx in range(len(dataset)):\n",
    "        x = dataset[idx][0]\n",
    "        y = dataset[idx][1]\n",
    "        norm_x = (x - min_x) / (max_x - min_x)\n",
    "        norm_y = (y - min_y) / (max_y - min_y)\n",
    "        normalized_dataset.append((norm_x, norm_y))\n",
    "    return normalized_dataset\n",
    "# Normalize the inputs and outputs using training dataset\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9a5986-5a8b-4962-9910-01747fac62c8",
   "metadata": {},
   "source": [
    "**Data Set**\n",
    "\n",
    "Load data\n",
    "\n",
    "Put in the right format \n",
    "\n",
    "Split training / validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b820e6-7664-4540-b430-bcfec4198e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_train_val_data = 80\n",
    "\n",
    "DEM_train_val = torch.zeros((length_train_val_data, 64, 64))\n",
    "\n",
    "training = 0.8\n",
    "validation = 0.2\n",
    "\n",
    "for k in range(length_train_val_data):\n",
    "    DEM = np.genfromtxt(f\"{folder}raw_datasets/DEM/DEM_{k+1}.txt\")\n",
    "    DEM_t = torch.as_tensor(DEM, dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    for x, y, elevation in zip(DEM_t[:,0], DEM_t[:,1], DEM_t[:,2]):\n",
    "        #Convert coordinates to indices in the 64x64 tensor\n",
    "        i = int((y - 50) / 100)\n",
    "        j = int((x - 50) / 100)\n",
    "        # Assign the elevation value to the corresponding position in the tensor\n",
    "        DEM_train_val[k, i, j] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54716180-e2de-4962-b468-5708037a4b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VX_train_val = torch.zeros((length_train_val_data, 97, 64, 64))\n",
    "\n",
    "training = 0.8\n",
    "validation = 0.2\n",
    "\n",
    "for k in range(length_train_val_data):\n",
    "    VX = np.genfromtxt(f\"{folder}raw_datasets/VX/VX_{k+1}.txt\")\n",
    "    VX_t = torch.as_tensor(VX, dtype=torch.float32)\n",
    "    \n",
    "    for x, y, elevation in zip(VX_t[:,0], VX_t[:,1], VX_t[:,2]):\n",
    "        # Convert coordinates to indices in the 64x64 tensor\n",
    "        i = int((y - 50) / 100)\n",
    "        j = int((x - 50) / 100)\n",
    "\n",
    "    # Assign the elevation value to the corresponding position in the tensor\n",
    "    VX_train_val[k, :, i, j] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f49d5f-8077-43d9-ac07-05a189d1320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VY_train_val = torch.zeros((length_train_val_data, 97, 64, 64))\n",
    "\n",
    "\n",
    "\n",
    "for k in range(length_train_val_data):\n",
    "    VY = np.genfromtxt(f\"{folder}raw_datasets/VY/VY_{k+1}.txt\")\n",
    "    VY_t = torch.as_tensor(VY, dtype=torch.float32)\n",
    "    \n",
    "    for x, y, elevation in zip(VY_t[:,0], VY_t[:,1], VY_t[:,2]):\n",
    "        # Convert coordinates to indices in the 64x64 tensor\n",
    "        i = int((y - 50) / 100)\n",
    "        j = int((x - 50) / 100)\n",
    "\n",
    "    # Assign the elevation value to the corresponding position in the tensor\n",
    "    VY_train_val[k, i, j] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e302c1e-af8c-43b0-b534-a8d2d0a71fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "WD_train_val = torch.zeros((length_train_val_data, 97, 64, 64))\n",
    "\n",
    "for i in range(length_train_val_data):\n",
    "    WD = np.genfromtxt(f\"{folder}raw_datasets/WD/WD_{i+1}.txt\")\n",
    "    WD_t = torch.as_tensor(WD, dtype=torch.float32)\n",
    "    for k in range(97):\n",
    "        wd = WD_t[k].reshape((64,64))\n",
    "        wd = torch.as_tensor(wd)\n",
    "\n",
    "    WD_train_val[i, k] = wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad29bad-1448-4fad-ac7a-513328cac0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have a tensor 'WD_train_val' with shape (length_train_val_data, 97, 64, 64)\n",
    "# WD_train_val_reshaped = torch.zeros((length_train_val_data, 24, 64, 64))\n",
    "\n",
    "# for i in range(length_train_val_data):\n",
    "#     WD = np.genfromtxt(f\"C:/Users/luc/Downloads/GitHub/FLOODS3_DSAIE/raw_datasets/WD//WD_{i+1}.txt\")\n",
    "#     WD_t = torch.as_tensor(WD, dtype=torch.float32)\n",
    "\n",
    "#     for j in range(24):\n",
    "#         # Extract a 2-hour interval from the original 97 time points\n",
    "#         start_index = j * 4  # Each 2-hour interval has 4 time points (assuming 30 minutes intervals)\n",
    "#         end_index = (j + 1) * 4\n",
    "#         wd = WD_t[j].reshape((64,64))\n",
    "#         wd = torch.tensor(wd)\n",
    "#         # Average or concatenate the data over the 2-hour interval, depending on your requirement\n",
    "#         wd_interval = torch.mean(wd[start_index:end_index], dim=0)  # You can use other aggregation functions if needed\n",
    "\n",
    "#         WD_train_val_reshaped[i, j] = wd_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f5f572-9068-40fb-9ab7-eb985ea3df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 97, 4, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "DEM_train_val_ex = DEM_train_val.unsqueeze(1).expand(-1, 97, -1, -1)\n",
    "\n",
    "input_train_dataset = torch.stack((DEM_train_val_ex, WD_train_val, VX_train_val, VY_train_val)).permute(1, 2, 0, 3, 4)\n",
    "print(input_train_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79af3fd-e308-48aa-a4ad-40c7cf204f32",
   "metadata": {},
   "source": [
    "**Normalize data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29e109c2-460f-481a-b130-d0f16c17b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation, and testing\n",
    "\n",
    "train_percnt = 0.8\n",
    "train_size = int(train_percnt * length_train_val_data)\n",
    "val_size = length_train_val_data - train_size\n",
    "train_dataset, val_dataset = random_split(input_train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5fb3c0f-ffa2-463d-9394-ab4525c7d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset, scaler_x, scaler_y):\n",
    "    min_x, max_x = scaler_x.data_min_[0], scaler_x.data_max_[0]\n",
    "    min_y, max_y = scaler_y.data_min_[0], scaler_y.data_max_[0]\n",
    "    normalized_dataset = []\n",
    "    for idx in range(len(dataset)):\n",
    "        x = dataset[idx][0]\n",
    "        y = dataset[idx][1]\n",
    "        norm_x = (x - min_x) / (max_x - min_x)\n",
    "        norm_y = (y - min_y) / (max_y - min_y)\n",
    "        normalized_dataset.append((norm_x, norm_y))\n",
    "    return normalized_dataset\n",
    "# Normalize the inputs and outputs using training dataset\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e149d9b-084a-471b-9b85-b3c7f89aa04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(train_dataset)):\n",
    "    scaler_x.partial_fit(train_dataset[idx][0].reshape(input_train_dataset.size(2), -1).T.cpu())\n",
    "    scaler_y.partial_fit(train_dataset[idx][1].reshape(-1, 1).cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77c3ec8b-feb1-4cb7-be6c-994c5247b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_test_data = 20\n",
    "\n",
    "DEM_test = torch.zeros((length_test_data, 64, 64))\n",
    "\n",
    "for k in range(length_test_data):\n",
    "    DEM = np.genfromtxt(f\"{folder}raw_datasets/VY/VY_{k+1}.txt\")\n",
    "    #\"C:\\Users\\luc\\Downloads\\GitHub\\FLOODS3_DSAIE\\raw_datasets\\DEM\"\n",
    "    DEM_t = torch.as_tensor(DEM, dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    for x, y, elevation in zip(DEM_t[:,0], DEM_t[:,1], DEM_t[:,2]):\n",
    "        #Convert coordinates to indices in the 64x64 tensor\n",
    "        i = int((y - 50) / 100)\n",
    "        j = int((x - 50) / 100)\n",
    "        # Assign the elevation value to the corresponding position in the tensor\n",
    "        DEM_test[k, i, j] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a55646-ade6-4151-b414-01dbad7df76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VX_test = torch.zeros((length_test_data, 97, 64, 64))\n",
    "\n",
    "for k in range(length_test_data):\n",
    "    VX = np.genfromtxt(f\"{folder}raw_datasets/VY/VY_{k+1}.txt\")\n",
    "    #\"C:\\Users\\luc\\Downloads\\GitHub\\FLOODS3_DSAIE\\raw_datasets\\DEM\"\n",
    "    VX_t = torch.as_tensor(DEM, dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    for x, y, elevation in zip(VX_t[:,0], VX_t[:,1], VX_t[:,2]):\n",
    "        #Convert coordinates to indices in the 64x64 tensor\n",
    "        i = int((y - 50) / 100)\n",
    "        j = int((x - 50) / 100)\n",
    "        # Assign the elevation value to the corresponding position in the tensor\n",
    "        VX_test[k, i, j] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e72706d-f896-4ee9-b3fd-7ea71dac1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VY_test = torch.zeros((length_test_data, 97, 64, 64))\n",
    "\n",
    "for k in range(length_test_data):\n",
    "    VY = np.genfromtxt(f\"raw_datasets/VY/VY_{k+1}.txt\")\n",
    "    #\"C:\\Users\\luc\\Downloads\\GitHub\\FLOODS3_DSAIE\\raw_datasets\\DEM\"\n",
    "    VY_t = torch.as_tensor(VY, dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    for x, y, elevation in zip(VY_t[:,0], VY_t[:,1], VY_t[:,2]):\n",
    "        #Convert coordinates to indices in the 64x64 tensor\n",
    "        i = int((y - 50) / 100)\n",
    "        j = int((x - 50) / 100)\n",
    "        # Assign the elevation value to the corresponding position in the tensor\n",
    "        VY_test[k, i, j] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "588afe13-db41-422d-8991-b3eef966ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WD_test = torch.zeros((length_test_data, 97, 64, 64))\n",
    "\n",
    "for k in range(length_test_data):\n",
    "    WD = np.genfromtxt(f\"{folder}raw_datasets/VY/VY_{k+1}.txt\")\n",
    "    #\"C:\\Users\\luc\\Downloads\\GitHub\\FLOODS3_DSAIE\\raw_datasets\\DEM\"\n",
    "    WD_t = torch.as_tensor(WD, dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    for x, y, elevation in zip(WD_t[:,0], WD_t[:,1], WD_t[:,2]):\n",
    "        #Convert coordinates to indices in the 64x64 tensor\n",
    "        i = int((y - 50) / 100)\n",
    "        j = int((x - 50) / 100)\n",
    "        # Assign the elevation value to the corresponding position in the tensor\n",
    "        WD_test[k, i, j] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d090fae4-0528-42fe-9db3-33e720698803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 97, 4, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "DEM_test_ex = DEM_test.unsqueeze(1).expand(-1, 97, -1, -1)\n",
    "\n",
    "test_dataset = torch.stack((DEM_test_ex, WD_test, VX_test, VY_test)).permute(1, 2, 0, 3, 4)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e1ba2-2dcb-4bf4-9e96-9c10f4c805b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8294eba7-7096-4507-8949-d598817b0c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_train_dataset = normalize_dataset(input_train_dataset, scaler_x, scaler_y)\n",
    "normalized_test_dataset = normalize_dataset(test_dataset, scaler_x, scaler_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239e10a-1246-4e8c-8ab3-937147c16a34",
   "metadata": {},
   "source": [
    "**Simple CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4367c283-542d-4dd5-bd91-ebed4b0b3091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, bias=False, batch_norm=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=bias)]\n",
    "        if batch_norm:\n",
    "            layers.append(nn.BatchNorm2d(num_features=out_channels))\n",
    "        layers.append(nn.PReLU())\n",
    "        layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=bias))\n",
    "                \n",
    "        self.cnnblock = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnnblock(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels=[32, 64, 128], kernel_size=3, padding=1, bias=False, batch_norm=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc_blocks = nn.ModuleList([\n",
    "            CNNBlock(channels[block], channels[block+1], kernel_size, padding, bias, \n",
    "                     batch_norm=batch_norm) \n",
    "            for block in range(len(channels)-1)]\n",
    "            )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            outs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return outs\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels=[128, 64, 32], kernel_size=3, padding=1, bias=False, batch_norm=True):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.upconvs = nn.ModuleList([\n",
    "            nn.ConvTranspose2d(channels[block], channels[block+1], kernel_size=2, padding=0, stride=2) \n",
    "            for block in range(len(channels)-1)]\n",
    "            )\n",
    "        self.dec_blocks = nn.ModuleList([\n",
    "            CNNBlock(channels[block], channels[block+1], kernel_size, padding, bias, \n",
    "                     batch_norm=batch_norm)\n",
    "             for block in range(len(channels)-1)]\n",
    "             )\n",
    "        \n",
    "    def forward(self, x, x_skips):\n",
    "        for i in range(len(x_skips)):\n",
    "            x = self.upconvs[i](x)\n",
    "            x = torch.cat((x, x_skips[-(1+i)]), dim=1)\n",
    "            x = self.dec_blocks[i](x)\n",
    "\n",
    "        x = self.dec_blocks[-1](x)\n",
    "        return x\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, node_features, out_dim=3, n_downsamples=3, initial_hid_dim=64, batch_norm=True, \n",
    "                 bias=True):\n",
    "        super(CNN, self).__init__()\n",
    "        hidden_channels = [initial_hid_dim*2**i for i in range(n_downsamples)]\n",
    "        encoder_channels = [node_features]+hidden_channels\n",
    "        decoder_channels = list(reversed(hidden_channels))+[out_dim]\n",
    "\n",
    "        self.encoder = Encoder(encoder_channels, kernel_size=3, padding=1, \n",
    "                               bias=bias, batch_norm=batch_norm)\n",
    "        self.decoder = Decoder(decoder_channels, kernel_size=3, padding=1, \n",
    "                               bias=bias, batch_norm=batch_norm)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x[-1], x[:-1])\n",
    "        x = nn.Sigmoid()(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5078bd5-ad10-43a6-a678-0cd3cf123ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "node_features = 4 #train_dataset[0][0].shape[0]\n",
    "print(node_features)\n",
    "model = CNN(node_features=node_features, n_downsamples=4, initial_hid_dim=32, \n",
    "            batch_norm=True, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25532c67-c5d6-402f-a3e5-5ef53d85bb11",
   "metadata": {},
   "source": [
    "**Training**\n",
    "\n",
    "How to make sure there are timesteps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf272607-918e-4ff5-a228-e366f8b136e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train() # specifies that the model is in training mode\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    # I do not know if this is the way to go, but now it calculates and backpropagates for each timestep in each batch\n",
    "    for batch in loader:\n",
    "        for t in range(1, len(batch[0])):\n",
    "            x = batch[0][t-1]\n",
    "            y = batch[0][t].unsqueeze(1)\n",
    "        \n",
    "            # Model prediction\n",
    "            preds = model(x)\n",
    "            # MSE loss function\n",
    "            loss = nn.MSELoss()(preds, y)\n",
    "            losses.append(loss.cpu().detach())\n",
    "            # Backpropagate and update weights\n",
    "            loss.backward()   # compute the gradients using backpropagation\n",
    "            optimizer.step()  # update the weights with the optimizer\n",
    "            optimizer.zero_grad(set_to_none=True)   # reset the computed gradients\n",
    "\n",
    "    losses = np.array(losses).mean()\n",
    "    print('train epoch complete')\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00927fbf-76e4-49c9-a8d2-85ab733c7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, loader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval() # specifies that the model is in evaluation mode\n",
    "    batch_n = 0\n",
    "    losses = []\n",
    "    \n",
    "    for batch in loader:\n",
    "        for t in range(1, len(batch[0])):\n",
    "            x = batch[0][t-1]\n",
    "            y = batch[0][t].unsqueeze(1)\n",
    "\n",
    "            # Model prediction\n",
    "            preds = model(x)\n",
    "\n",
    "            # MSE loss function\n",
    "            loss = nn.MSELoss()(preds, y)\n",
    "            losses.append(loss.cpu().detach())\n",
    "        loss = np.array(losses).mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77128007-02cd-4af0-8772-72112435b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 1\n",
    "num_epochs = 10\n",
    "\n",
    "# Create the optimizer to train the neural network via back-propagation\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the training and validation dataloaders to \"feed\" data to the model in batches\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "# test_loader = DataLoader(normalized_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a119af7-5f6e-46b8-b585-274d51fd045c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Model training\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Model validation\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluation(model, val_loader, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m][t]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Model prediction\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# MSE loss function\u001b[39;00m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()(preds, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 73\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     72\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], x[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     75\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSigmoid()(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 30\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m outs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_blocks:\n\u001b[0;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     outs\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m, in \u001b[0;36mCNNBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnnblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsaie/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device"
     ]
    }
   ],
   "source": [
    "#create vectors for the training and validation loss\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    # Model training\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device=device)\n",
    "\n",
    "    # Model validation\n",
    "    val_loss = evaluation(model, val_loader, device=device)\n",
    "\n",
    "    if epoch == 1:\n",
    "        best_loss = val_loss\n",
    "\n",
    "    if val_loss<=best_loss:\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "        print(\"epoch:\",epoch, \"\\t training loss:\", np.round(train_loss,4),\n",
    "                            \"\\t validation loss:\", np.round(val_loss,4))\n",
    "\n",
    "model = copy.deepcopy(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289bcf8-1f6a-4545-a0d5-0e4ec736dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"epoch:\",epoch, \"\\t training loss:\", np.round(train_loss,4),\n",
    "                            \"\\t validation loss:\", np.round(val_loss,4))\n",
    "model = copy.deepcopy(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33434b7e-4abe-48ee-9224-ef27601b0b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.yscale('log')\n",
    "plt.title('Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e1011-b021-41c7-bfb6-fdf01651289e",
   "metadata": {},
   "source": [
    "**Testing**\n",
    "\n",
    "I have not done this, the code below is copied does not work yet!\n",
    "\n",
    "Model is untested!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d420e-510c-441e-8869-16ae23c90118",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluation(model, test_loader, device=device)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3aa9f2-e12b-4f6c-a794-b0fe014d1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one sample\n",
    "data_id = 10\n",
    "\n",
    "x = normalized_test_dataset[data_id][0].unsqueeze(0)\n",
    "FAT = normalized_test_dataset[data_id][1]\n",
    "\n",
    "# predict the FAT\n",
    "pred_FAT = model(x).detach() # I\n",
    "\n",
    "print(pred_FAT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c23d8f-9425-41bc-b178-771a5cc3677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEM = scaler_x.inverse_transform(x[0].reshape(2,-1).T.cpu())[:,0].reshape(64,64)\n",
    "real_FAT = scaler_y.inverse_transform(FAT[-1].reshape(-1, 1).cpu()).reshape(64,64)\n",
    "# real_FAT_2 = scaler_y.inverse_transform(FAT.reshape(96,-1).T.cpu()).reshape(64,64)\n",
    "\n",
    "pred_FAT = scaler_y.inverse_transform(pred_FAT[0][-1].reshape(-1,1).cpu()).reshape(64,64)\n",
    "# pred_FAT_2 = scaler_y.inverse_transform(pred_FAT.reshape(96,-1).T.cpu()).reshape(64,64)\n",
    "\n",
    "print(real_FAT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0cb55-5e02-4d99-9275-8c9efd6f319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(17,5))\n",
    "\n",
    "diff_FAT = real_FAT - pred_FAT\n",
    "max_FAT = max(pred_FAT.max(), real_FAT.max())\n",
    "max_diff = max(diff_FAT.max(), -diff_FAT.min())\n",
    "\n",
    "axs[0].imshow(DEM.squeeze(), cmap='terrain', origin='lower')\n",
    "axs[1].imshow(real_FAT.squeeze(), vmin = 0, vmax=max_FAT, cmap='Blues_r', origin='lower')\n",
    "axs[2].imshow(pred_FAT.squeeze(), vmin = 0, vmax=max_FAT,cmap='Blues_r', origin='lower')\n",
    "axs[3].imshow(diff_FAT.squeeze(), vmin=-max_diff, vmax=max_diff, cmap='RdBu', origin='lower')\n",
    "\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = DEM.min(), vmax=DEM.max()),\n",
    "                            cmap='terrain'), fraction=0.05, shrink=0.9, ax=axs[0])\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = 0, vmax=max_FAT),\n",
    "                            cmap='Blues_r'), fraction=0.05, shrink=0.9, ax=axs[1])\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = 0, vmax=max_FAT),\n",
    "                            cmap='Blues_r'), fraction=0.05, shrink=0.9, ax=axs[2])\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=TwoSlopeNorm(vmin=-max_diff, vmax=max_diff, vcenter=0),\n",
    "                            cmap='RdBu'), fraction=0.05, shrink=0.9, ax=axs[3])\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "axs[0].set_title('DEM')\n",
    "axs[1].set_title('Real FAT (h)')\n",
    "axs[2].set_title('Predicted FAT (h)')\n",
    "axs[3].set_title('Difference (h)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdd7e8-8aa6-4abe-866c-b20c7d5d02c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f771db6-6db9-45d9-a336-c3887124cd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4538b4e-0d9d-4ea2-a90d-320ec79c28f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af484e73-2f2e-459c-ba30-f1d267cce0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
