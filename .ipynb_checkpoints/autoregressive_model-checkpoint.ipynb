{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Useful libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "from cycler import cycler\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the color scheme\n",
    "sns.set_theme()\n",
    "colors = ['#0076C2', '#EC6842', '#A50034', '#009B77', '#FFB81C', '#E03C31', '#6CC24A', '#EF60A3', '#0C2340', '#00B8C8', '#6F1D77']\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color=colors)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_train_val_data = 80\n",
    "\n",
    "DEM_train_val = torch.zeros((length_train_val_data, 64, 64))\n",
    "\n",
    "training = 0.8\n",
    "validation = 0.2\n",
    "\n",
    "for k in range(length_train_val_data):\n",
    "  DEM = np.genfromtxt(f'raw_datasets/DEM/DEM_{k+1}.txt')\n",
    "  DEM_t = torch.as_tensor(DEM, dtype=torch.float32)\n",
    "\n",
    "\n",
    "  for x, y, elevation in zip(DEM_t[:,0], DEM_t[:,1], DEM_t[:,2]):\n",
    "      # Convert coordinates to indices in the 64x64 tensor\n",
    "      i = int((y - 50) / 100)\n",
    "      j = int((x - 50) / 100)\n",
    "\n",
    "      # Assign the elevation value to the corresponding position in the tensor\n",
    "      DEM_train_val[k, i, j] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VX_train_val = torch.zeros((length_train_val_data, 97, 64, 64))\n",
    "\n",
    "training = 0.8\n",
    "validation = 0.2\n",
    "\n",
    "for k in range(length_train_val_data):\n",
    "  VX = np.genfromtxt(f'raw_datasets/VX/VX_{k+1}.txt')\n",
    "  VX_t = torch.as_tensor(VX, dtype=torch.float32)\n",
    "\n",
    "\n",
    "  for x, y, elevation in zip(VX_t[:,0], VX_t[:,1], VX_t[:,2]):\n",
    "      # Convert coordinates to indices in the 64x64 tensor\n",
    "      i = int((y - 50) / 100)\n",
    "      j = int((x - 50) / 100)\n",
    "\n",
    "      # Assign the elevation value to the corresponding position in the tensor\n",
    "      VX_train_val[k, :, i, j] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vDxq0tOGHtym"
   },
   "outputs": [],
   "source": [
    "VY_train_val = torch.zeros((length_train_val_data, 97, 64, 64))\n",
    "\n",
    "training = 0.8\n",
    "validation = 0.2\n",
    "\n",
    "for k in range(length_train_val_data):\n",
    "  VY = np.genfromtxt(f'raw_datasets/VY/VY_{k+1}.txt')\n",
    "  VY_t = torch.as_tensor(VY, dtype=torch.float32)\n",
    "\n",
    "\n",
    "  for x, y, elevation in zip(VY_t[:,0], VY_t[:,1], VY_t[:,2]):\n",
    "      # Convert coordinates to indices in the 64x64 tensor\n",
    "      i = int((y - 50) / 100)\n",
    "      j = int((x - 50) / 100)\n",
    "\n",
    "      # Assign the elevation value to the corresponding position in the tensor\n",
    "      VY_train_val[k, i, j] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "F_F6k4QGIyOe"
   },
   "outputs": [],
   "source": [
    "WD_train_val = torch.zeros((length_train_val_data, 97, 64, 64))\n",
    "\n",
    "training = 0.8\n",
    "validation = 0.2\n",
    "\n",
    "for i in range(length_train_val_data):\n",
    "  WD = np.genfromtxt(f'raw_datasets/WD/WD_{i+1}.txt')\n",
    "  WD_t = torch.as_tensor(WD, dtype=torch.float32)\n",
    "\n",
    "  for k in range(97):\n",
    "    wd = WD_t[k].reshape((64,64))\n",
    "    wd = torch.as_tensor(wd)\n",
    "\n",
    "    WD_train_val[i, k] = wd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ao8LvyT-W1Hd"
   },
   "outputs": [],
   "source": [
    "length_train_val_data = 80\n",
    "\n",
    "# Assuming you have a tensor 'WD_train_val' with shape (length_train_val_data, 97, 64, 64)\n",
    "WD_train_val_reshaped = torch.zeros((length_train_val_data, 24, 64, 64))\n",
    "\n",
    "for i in range(length_train_val_data):\n",
    "    WD = np.genfromtxt(f'raw_datasets/WD/WD_{i+1}.txt')\n",
    "    WD_t = torch.as_tensor(WD, dtype=torch.float32)\n",
    "\n",
    "    for j in range(24):\n",
    "        # Extract a 2-hour interval from the original 97 time points\n",
    "        start_index = j * 4  # Each 2-hour interval has 4 time points (assuming 30 minutes intervals)\n",
    "        end_index = (j + 1) * 4\n",
    "        wd = WD_t[j].reshape((64,64))\n",
    "        wd = torch.as_tensor(wd)\n",
    "        # Average or concatenate the data over the 2-hour interval, depending on your requirement\n",
    "        wd_interval = torch.mean(wd[start_index:end_index], dim=0)  # You can use other aggregation functions if needed\n",
    "\n",
    "        WD_train_val_reshaped[i, j] = wd_interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8x3Lkd5qUcfw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "e4YnB_9BDg42"
   },
   "outputs": [],
   "source": [
    "input_train_dataset = torch.stack((DEM_train_val, WD_train_val[:,0])).permute(1, 0, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "k1Gf6V_gJ7Cg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 2, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(input_train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XjJHV1cmzchs"
   },
   "outputs": [],
   "source": [
    "output_train_dataset = WD_train_val[:,1:97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "M0CPWl0LzpPW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 96, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(output_train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "p19UN3cQYijy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 2)\n",
      "torch.Size([96, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bkrans/miniconda3/envs/dsaie/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2009: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  result = asarray(a).shape\n",
      "/Users/bkrans/miniconda3/envs/dsaie/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    }
   ],
   "source": [
    "train_dataset = []\n",
    "\n",
    "# Iterate through the samples\n",
    "for i in range(input_train_dataset.size(0)):\n",
    "    # Get the tensors for the current sample\n",
    "    sample_tensor1 = input_train_dataset[i]  # Shape: [2, 64, 64]\n",
    "    sample_tensor2 = output_train_dataset[i]  # Shape: [96, 64, 64]\n",
    "\n",
    "    # Append the tensors to the train_dataset list\n",
    "    train_dataset.append([sample_tensor1, sample_tensor2])\n",
    "\n",
    "# Convert the list to a PyTorch tensor\n",
    "# train_dataset = torch.stack([torch.stack(sample) for sample in train_dataset])\n",
    "\n",
    "print(np.shape(train_dataset))\n",
    "\n",
    "print(np.shape(train_dataset[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AOpAjEKIZNQF"
   },
   "outputs": [],
   "source": [
    "# print(train_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQI5pOJYfO8N"
   },
   "source": [
    "Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xeBP6f06fOO3"
   },
   "outputs": [],
   "source": [
    "length_test_data = 20\n",
    "\n",
    "DEM_test = torch.zeros((length_test_data, 64, 64))\n",
    "\n",
    "training = 0.8\n",
    "validation = 0.2\n",
    "\n",
    "for k in range(length_test_data):\n",
    "  DEM = np.genfromtxt(f'raw_datasets/DEM/DEM_{k+500}.txt')\n",
    "\n",
    "  DEM_t = torch.as_tensor(DEM, dtype=torch.float32)\n",
    "\n",
    "\n",
    "  for x, y, elevation in zip(DEM_t[:,0], DEM_t[:,1], DEM_t[:,2]):\n",
    "      # Convert coordinates to indices in the 64x64 tensor\n",
    "      i = int((y - 50) / 100)\n",
    "      j = int((x - 50) / 100)\n",
    "\n",
    "      # Assign the elevation value to the corresponding position in the tensor\n",
    "      DEM_test[k, i, j] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gNyk4XtRf6zC"
   },
   "outputs": [],
   "source": [
    "WD_test = torch.zeros((length_test_data, 97, 64, 64))\n",
    "\n",
    "training = 0.8\n",
    "validation = 0.2\n",
    "\n",
    "for i in range(length_test_data):\n",
    "  WD = np.genfromtxt(f'raw_datasets/WD/WD_{i+500}.txt')\n",
    "  WD_t = torch.as_tensor(WD, dtype=torch.float32)\n",
    "\n",
    "  for k in range(97):\n",
    "    wd = WD_t[k].reshape((64,64))\n",
    "    wd = torch.as_tensor(wd)\n",
    "\n",
    "    WD_test[i, k] = wd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Ckiqw-dxglcd"
   },
   "outputs": [],
   "source": [
    "length_test_data = 20\n",
    "\n",
    "# Assuming you have a tensor 'WD_train_val' with shape (length_train_val_data, 97, 64, 64)\n",
    "WD_test_reshaped = torch.zeros((length_test_data, 24, 64, 64))\n",
    "\n",
    "for i in range(length_test_data):\n",
    "    WD = np.genfromtxt(f'raw_datasets/WD/WD_{i+500}.txt')\n",
    "    WD_t = torch.as_tensor(WD, dtype=torch.float32)\n",
    "\n",
    "    for j in range(24):\n",
    "        # Extract a 2-hour interval from the original 97 time points\n",
    "        start_index = j * 4  # Each 2-hour interval has 4 time points (assuming 30 minutes intervals)\n",
    "        end_index = (j + 1) * 4\n",
    "        wd = WD_t[j].reshape((64,64))\n",
    "        wd = torch.as_tensor(wd)\n",
    "        # Average or concatenate the data over the 2-hour interval, depending on your requirement\n",
    "        wd_interval = torch.mean(wd[start_index:end_index], dim=0)  # You can use other aggregation functions if needed\n",
    "\n",
    "        WD_test_reshaped[i, j] = wd_interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "b98DCTmRiWCA"
   },
   "outputs": [],
   "source": [
    "input_test_dataset = torch.stack((DEM_test, WD_test[:,0])).permute(1, 0, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Z1LeLlMDiWRu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(input_test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FRyd5zqqiWbb"
   },
   "outputs": [],
   "source": [
    "output_test_dataset = WD_test[:,1:97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "pN9QGSG3i19N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 96, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(output_test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "P3rbS94Yi7Ki"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2)\n",
      "torch.Size([96, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "test_dataset = []\n",
    "\n",
    "# Iterate through the samples\n",
    "for i in range(input_test_dataset.size(0)):\n",
    "    # Get the tensors for the current sample\n",
    "    sample_tensor1 = input_test_dataset[i]  # Shape: [2, 64, 64]\n",
    "    sample_tensor2 = output_test_dataset[i]  # Shape: [96, 64, 64]\n",
    "\n",
    "    # Append the tensors to the train_dataset list\n",
    "    test_dataset.append([sample_tensor1, sample_tensor2])\n",
    "\n",
    "# Convert the list to a PyTorch tensor\n",
    "# train_dataset = torch.stack([torch.stack(sample) for sample in train_dataset])\n",
    "\n",
    "print(np.shape(test_dataset))\n",
    "\n",
    "print(np.shape(test_dataset[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        # RNN layer\n",
    "        self.rnn = nn.RNN(input_size=1, hidden_size=hidden_size, batch_first=True)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input to have feature dimension of 1\n",
    "        x = x.unsqueeze(-1)   # Assuming input x has shape (batch, sequence)\n",
    "\n",
    "        # RNN layer\n",
    "        x, hn = self.rnn(x)   # We do not need the hidden states hn\n",
    "\n",
    "        # Select the output of the last time step\n",
    "        x = x[:, -1, :]\n",
    "\n",
    "        # Output layer\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model multistep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_multistep(model, test_loader, criterion, device, T, H):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "\n",
    "    all_predictions = []  # List to store all batch predictions\n",
    "    all_targets = []      # List to store all batch targets\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for initial_inputs, initial_targets in test_loader:\n",
    "            step_inputs = initial_inputs.to(device)\n",
    "            targets = initial_targets.to(device)\n",
    "\n",
    "            # Holds predictions for comparison with targets\n",
    "            predictions = []\n",
    "\n",
    "            # Iterate for H steps\n",
    "            for h in range(H):\n",
    "                outputs = model(step_inputs)\n",
    "                predictions.append(outputs)\n",
    "\n",
    "                # Reshape or expand outputs to be 3D: [batch_size, 1, features]\n",
    "                next_input = outputs.unsqueeze(-1).squeeze(1)  # Adjust the dimensions as necessary\n",
    "\n",
    "                # Update step_inputs by sliding the window: remove the oldest input and add the new output\n",
    "                # Ensure that step_inputs and next_input are correctly shaped for concatenation\n",
    "                step_inputs = torch.cat((step_inputs[:, 1:], next_input), dim=1)\n",
    "\n",
    "            # Concatenate predictions and calculate loss against the entire target sequence\n",
    "            batch_predictions  = torch.stack(predictions, dim=1).squeeze(-1)  # Squeeze the last dimension\n",
    "\n",
    "            loss = criterion(batch_predictions , targets)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Store batch predictions and targets\n",
    "            all_predictions.append(batch_predictions.cpu())\n",
    "            all_targets.append(targets.cpu())\n",
    "\n",
    "    # Concatenate all batch predictions and targets into tensors\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    return avg_test_loss, all_predictions, all_targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
